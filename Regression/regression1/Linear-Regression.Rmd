---
title: "Regression Notebook"
output: html_notebook
---



- In our Train data, Random relation between 'x' and 'y' is given. Based on that analysis ,We have to find the corrosponding 'y' for given 'x' in test-data.We can use        linear regression to find a relation between 'x' and 'y' based on that relation, we can predict our ans.

- So let's Start, with importing library , which will be used later...

```{r}
library(ggplot2)
```

- Now, It's time to call data here, so import that too...

```{r}
trainSet = read.csv('/home/kunal/Documents/DS/Linear-Regression/Data/train.csv')
head(trainSet)
```

- So now, we have data. let's check out for missing value in given training data.
  Because , missing data is of no use for us.
  
```{r}
numberOfNA = length(which(is.na(trainSet)==T))
if(numberOfNA > 0) {
  cat('Oh shit...!!! Missing values found: ', numberOfNA)
  cat('\nRemoving missing values...')
  trainSet = trainSet[complete.cases(trainSet), ]
}
```

- Ok, Data is complete now, no missing... ok Good!!!
- Now, let me check for outlier...
- Okey, Actually Outliers are the value that is far distant from other neighbour
  suppose, we have data for age: 12,11,14,13,12,123,10
  So, in above eg. certainly we have age value 123, i.e. Outlier. It may be some error during data collection.

```{r}
# Divide the graph area in 2 columns
par(mfrow = c(1, 2))
# Boxplot for X
boxplot(trainSet$x, main='X', sub=paste('Outliers: ', boxplot.stats(trainingSet$x)$out))
# Boxplot for Y
boxplot(trainSet$y, main='Y', sub=paste('Outliers: ', boxplot.stats(trainingSet$y)$out))
```


- We can clearly see that we have Two outlier in 'x' coloumn. So we need to remove it.
  So let's create a function for that.


```{r}
#Function To remove Outlier
outlierKD <- function(dt, var) {
     var_name <- eval(substitute(var),eval(dt))
     na1 <- sum(is.na(var_name))
     m1 <- mean(var_name, na.rm = T)
     par(mfrow=c(2, 2), oma=c(0,0,3,0))
     boxplot(var_name, main="With outliers")
     hist(var_name, main="With outliers", xlab=NA, ylab=NA)
     outlier <- boxplot.stats(var_name)$out
     mo <- mean(outlier)
     var_name <- ifelse(var_name %in% outlier, NA, var_name)
     boxplot(var_name, main="Without outliers")
     hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
     title("Outlier Check", outer=TRUE)
     na2 <- sum(is.na(var_name))
     cat("Outliers identified:", na2 - na1, "\n")
     cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "n")
     cat("Mean of the outliers:", round(mo, 2), "\n")
     m2 <- mean(var_name, na.rm = T)
     cat("Mean without removing outliers:", round(m1, 2), "\n")
     cat("Mean if we remove outliers:", round(m2, 2), "\n")
     response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
     if(response == "y" | response == "yes"){
          dt[as.character(substitute(var))] <- invisible(var_name)
          assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
          cat("Outliers successfully removed", "\n")
          return(invisible(dt))
     } else{
          cat("Nothing changed", "\n")
          return(invisible(var_name))
     }
}
```

```{r}
# Run the function to remove outlier, pass data set and var ... we have outlier in 'x' .
outlierKD(trainSet,x)
```


```{r}
#check data again for missing value
numberOfNA = length(which(is.na(trainSet)==T))
if(numberOfNA > 0) {
  cat('Oh shit...!!! Missing values found: ', numberOfNA)
  cat('\nRemoving missing values...')
  trainSet = trainSet[complete.cases(trainSet), ]
}
```


- Now data is clean , So proceed further.. 
- Find Correlation ???
  Correlation is a statistical measure that suggests the level of linear dependence between two variables,
  that occur in pair.Its value lies between -1 to +1.

```{r}
cor(trainSet$x, trainSet$y)
```

- Now, create Regression
```{r}
reg = lm(formula = y ~.,
               data = trainSet)
```

- Have a look at regression...

```{r}
summary(reg)
```

#### Have look at Traing set...

```{r}
ggplot() +
  geom_point(aes(x = trainSet$x, y = trainSet$y),
             colour = 'red') +
  geom_line(aes(x = trainSet$x, y = predict(reg, newdata = trainSet)),
            colour = 'blue') +
  ggtitle('X vs Y (Train set)') +
  xlab('X') +
  ylab('Y')
```


- Above plot clearly shows that..there is a linear relationship between x and y which is continous in nature.

- So now it's time to bring Test-data...

```{r}
# Importing test data
testSet = read.csv('/home/kunal/Documents/DS/Linear-Regression/Data/test.csv')
# Predicting the test results
y_pred = predict(reg, newdata = testSet)
```

#### Now have a look at test data...

```{r}
ggplot() +
  geom_point(aes(x = testSet$x, y = testSet$y),
             colour = 'red') +
  geom_line(aes(x = trainSet$x, y = predict(reg, newdata = trainSet)),
            colour = 'blue') +
  ggtitle('X vs Y (Test set)') +
  xlab('X') +
  ylab('Y')
```



- Everything looks good , but ... just check for accuracy again...

```{r}
compare <- cbind (actual=testSet$x, y_pred)  # combine actual and predicted
mean (apply(compare, 1, min)/apply(compare, 1, max))
mean(0.9,0.9,0.9,0.9)
```


##### Yeah... Right!!!

